#!/usr/bin/env python3
"""
Complete GHRB dataset setup with verification.
Downloads repositories, extracts bug reports, and prepares for evaluation.
"""

import subprocess
import json
from pathlib import Path
import tarfile
import requests
from tqdm import tqdm
import sys

def download_file(url, output_path):
    """Download file with progress bar."""
    print(f"\nüì• Downloading to {output_path.name}...")
    
    try:
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        with open(output_path, 'wb') as f, tqdm(
            desc=output_path.name,
            total=total_size,
            unit='iB',
            unit_scale=True,
            unit_divisor=1024,
        ) as pbar:
            for data in response.iter_content(chunk_size=8192):
                size = f.write(data)
                pbar.update(size)
        
        print(f"‚úì Downloaded: {output_path.name} ({total_size / (1024*1024):.1f} MB)")
        return True
        
    except Exception as e:
        print(f"‚úó Download failed: {e}")
        return False

def extract_tarball(tar_path, extract_to):
    """Extract tarball with progress."""
    print(f"\nüì¶ Extracting {tar_path.name}...")
    
    try:
        extract_to.mkdir(parents=True, exist_ok=True)
        
        with tarfile.open(tar_path, 'r:gz') as tar:
            members = tar.getmembers()
            
            for member in tqdm(members, desc="Extracting"):
                tar.extract(member, extract_to)
        
        print(f"‚úì Extracted to: {extract_to}")
        return True
        
    except Exception as e:
        print(f"‚úó Extraction failed: {e}")
        return False

def verify_setup():
    """Verify GHRB setup is complete."""
    print("\nüîç Verifying setup...")
    
    base_dir = Path("data/GHRB")
    repos_dir = base_dir / "repos"
    
    issues = []
    
    # Check repos directory
    if not repos_dir.exists():
        issues.append("Repositories directory not found")
    else:
        repos = list(repos_dir.iterdir())
        if len(repos) == 0:
            issues.append("No repositories found")
        else:
            print(f"  ‚úì Found {len(repos)} repositories")
    
    if issues:
        print("\n‚ö†Ô∏è  Issues found:")
        for issue in issues:
            print(f"  - {issue}")
        return False
    
    print("‚úì Setup verification passed")
    return True

def main():
    """Setup GHRB dataset."""
    
    print("=" * 80)
    print("üöÄ GHRB Dataset Setup")
    print("=" * 80)
    print("\nThis will download ~2-3 GB of data")
    print("Estimated time: 10-30 minutes depending on connection")
    
    base_dir = Path("data/GHRB")
    base_dir.mkdir(parents=True, exist_ok=True)
    
    # Step 1: Download repositories
    print("\n" + "=" * 80)
    print("Step 1: Download GHRB Repositories")
    print("=" * 80)
    
    repos_tar = base_dir / "ghrb-repos.tar.gz"
    repos_url = "https://figshare.com/ndownloader/files/37005352?private_link=de40ea0a3dea94560e84"
    
    if repos_tar.exists():
        print(f"‚úì Repository archive already exists ({repos_tar.stat().st_size / (1024*1024):.1f} MB)")
        response = input("Download again? (y/N): ").strip().lower()
        if response == 'y':
            repos_tar.unlink()
        else:
            print("Skipping download")
    
    if not repos_tar.exists():
        success = download_file(repos_url, repos_tar)
        if not success:
            print("\n‚úó Failed to download repositories")
            sys.exit(1)
    
    # Step 2: Extract repositories
    print("\n" + "=" * 80)
    print("Step 2: Extract Repositories")
    print("=" * 80)
    
    repos_dir = base_dir / "repos"
    
    if repos_dir.exists() and list(repos_dir.iterdir()):
        print(f"‚úì Repositories already extracted")
        response = input("Extract again? (y/N): ").strip().lower()
        if response == 'y':
            import shutil
            shutil.rmtree(repos_dir)
        else:
            print("Skipping extraction")
    
    if not repos_dir.exists() or not list(repos_dir.iterdir()):
        success = extract_tarball(repos_tar, repos_dir)
        if not success:
            print("\n‚úó Failed to extract repositories")
            sys.exit(1)
    
    # Step 3: Download generated tests (optional, for reference)
    print("\n" + "=" * 80)
    print("Step 3: Download Generated Tests (Optional)")
    print("=" * 80)
    print("These are tests generated by the original paper for comparison")
    
    tests_tar = base_dir / "ghrb-gen-tests.tar.gz"
    tests_url = "https://figshare.com/ndownloader/files/37005343?private_link=de40ea0a3dea94560e84"
    
    response = input("Download generated tests? (y/N): ").strip().lower()
    
    if response == 'y':
        if not tests_tar.exists():
            success = download_file(tests_url, tests_tar)
            if success:
                tests_dir = base_dir / "gen_tests"
                extract_tarball(tests_tar, tests_dir)
        else:
            print("‚úì Tests archive already exists")
    else:
        print("Skipping generated tests download")
    
    # Verify setup
    verify_setup()
    
    # Show what we have
    print("\n" + "=" * 80)
    print("‚úÖ GHRB Setup Complete!")
    print("=" * 80)
    
    if repos_dir.exists():
        repo_list = sorted([d for d in repos_dir.iterdir() if d.is_dir()])
        print(f"\nüìÇ Repositories ({len(repo_list)}):")
        for repo in repo_list:
            # Count Java files
            java_files = list(repo.rglob("*.java"))
            print(f"  ‚úì {repo.name:30s} ({len(java_files):4d} Java files)")
    
    print("\n" + "=" * 80)
    print("Next Steps:")
    print("  1. Run: python3 scripts/extract_ghrb_bugs.py")
    print("  2. Run: python3 scripts/run_ghrb_evaluation.py")
    print("=" * 80)

if __name__ == "__main__":
    main()

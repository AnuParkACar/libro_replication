{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Generation on Google Colab\n",
    "Generate tests for bugs using GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive for persistence\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set working directory\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/libro_replication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!pip install transformers torch accelerate huggingface_hub sentencepiece -q\n",
    "!pip install tqdm pyyaml -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone/pull repository code\n",
    "# (Assumes you've uploaded your code to Drive)\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/libro_replication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Login to HuggingFace\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import json\n",
    "import logging\n",
    "from src.model_manager import ModelManager\n",
    "from src.core.prompt_builder import PromptBuilder\n",
    "from src.core.test_generator import TestGenerator\n",
    "from src.core.batch_processor import BatchProcessor\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load bug reports\n",
    "with open('data/bugs/bug_reports.json') as f:\n",
    "    bug_reports = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(bug_reports)} bug reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize model (use StarCoder2-15B on A100)\n",
    "model_manager = ModelManager(\n",
    "    model_key=\"starcoder2-15b\",\n",
    "    cache_dir=\"models/starcoder2-15b\"\n",
    ")\n",
    "model_manager.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize components\n",
    "prompt_builder = PromptBuilder(\n",
    "    num_examples=2,\n",
    "    examples_file=\"data/examples/manual_examples.json\"\n",
    ")\n",
    "\n",
    "test_generator = TestGenerator(\n",
    "    model_manager=model_manager,\n",
    "    cache_dir=\"cache/generations\"\n",
    ")\n",
    "\n",
    "batch_processor = BatchProcessor(\n",
    "    prompt_builder=prompt_builder,\n",
    "    test_generator=test_generator,\n",
    "    output_dir=\"results/batch_30\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process bugs (30 bugs, 10 samples each)\n",
    "results = batch_processor.process_bugs(\n",
    "    bug_reports=bug_reports[:30],\n",
    "    n_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# View results summary\n",
    "print(f\"\\nProcessed {len(results)} bugs\")\n",
    "print(f\"Total tests generated: {sum(len(tests) for tests in results.values())}\")\n",
    "\n",
    "# Show sample\n",
    "for bug_id, tests in list(results.items())[:3]:\n",
    "    print(f\"\\n{bug_id}: {len(tests)} tests\")\n",
    "    if tests:\n",
    "        print(tests[0]['test_code'][:150])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100"
  }
 }
}
